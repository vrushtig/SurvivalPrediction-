{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNIWRzotKVFGj8EBclM9F4x"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHlvpVHlXK7t",
        "outputId": "5192dc2d-9358-481e-af31-ce874c4ea883"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4024 entries, 0 to 4023\n",
            "Data columns (total 16 columns):\n",
            " #   Column                  Non-Null Count  Dtype  \n",
            "---  ------                  --------------  -----  \n",
            " 0   Age                     3823 non-null   float64\n",
            " 1   Race                    3622 non-null   object \n",
            " 2   Marital Status          3703 non-null   object \n",
            " 3   T Stage                 4024 non-null   object \n",
            " 4   N Stage                 4024 non-null   object \n",
            " 5   6th Stage               4024 non-null   object \n",
            " 6   differentiate           4024 non-null   object \n",
            " 7   Grade                   4024 non-null   object \n",
            " 8   A Stage                 4024 non-null   object \n",
            " 9   Tumor Size              3622 non-null   float64\n",
            " 10  Estrogen Status         3823 non-null   object \n",
            " 11  Progesterone Status     4024 non-null   object \n",
            " 12  Regional Node Examined  3421 non-null   float64\n",
            " 13  Reginol Node Positive   4024 non-null   int64  \n",
            " 14  Survival Months         4024 non-null   int64  \n",
            " 15  Status                  4024 non-null   object \n",
            "dtypes: float64(3), int64(2), object(11)\n",
            "memory usage: 503.1+ KB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None,\n",
              "     Age   Race Marital Status T Stage  N Stage 6th Stage  \\\n",
              " 0  68.0  White        Married       T1      N1       IIA   \n",
              " 1  50.0  White            NaN       T2      N2      IIIA   \n",
              " 2  58.0  White       Divorced       T3      N3      IIIC   \n",
              " 3  58.0  White        Married       T1      N1       IIA   \n",
              " 4  47.0  White        Married       T2      N1       IIB   \n",
              " \n",
              "                differentiate Grade   A Stage  Tumor Size Estrogen Status  \\\n",
              " 0      Poorly differentiated     3  Regional         4.0        Positive   \n",
              " 1  Moderately differentiated     2  Regional        35.0        Positive   \n",
              " 2  Moderately differentiated     2  Regional        63.0        Positive   \n",
              " 3      Poorly differentiated     3  Regional         NaN        Positive   \n",
              " 4      Poorly differentiated     3  Regional        41.0             NaN   \n",
              " \n",
              "   Progesterone Status  Regional Node Examined  Reginol Node Positive  \\\n",
              " 0            Positive                    24.0                      1   \n",
              " 1            Positive                    14.0                      5   \n",
              " 2            Positive                    14.0                      7   \n",
              " 3            Positive                     2.0                      1   \n",
              " 4            Positive                     3.0                      1   \n",
              " \n",
              "    Survival Months Status  \n",
              " 0               60  Alive  \n",
              " 1               62  Alive  \n",
              " 2               75  Alive  \n",
              " 3               84  Alive  \n",
              " 4               50  Alive  )"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data_path = data_path = '/content/Breast_Cancer_dataset.csv'\n",
        "data = pd.read_csv(data_path)\n",
        "\n",
        "data_info = data.info()\n",
        "data_head = data.head()\n",
        "\n",
        "data_info, data_head\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 1: handling missing values using SimpleImputer\n",
        "# for numerical columns, used mean imputation, for categorical - mode imputation\n",
        "\n",
        "# Separate numerical and categorical columns\n",
        "num_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
        "cat_cols = data.select_dtypes(include=['object']).columns\n",
        "\n",
        "# impute missing values\n",
        "imputer_num = SimpleImputer(strategy='mean')\n",
        "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "data[num_cols] = imputer_num.fit_transform(data[num_cols])\n",
        "data[cat_cols] = imputer_cat.fit_transform(data[cat_cols])\n",
        "\n",
        "# Step 2: standardize numerical features\n",
        "scaler = StandardScaler()\n",
        "data[num_cols] = scaler.fit_transform(data[num_cols])\n",
        "\n",
        "missing_after_imputation = data.isnull().sum().sum()\n",
        "data_head_after_processing = data.head()\n",
        "\n",
        "missing_after_imputation, data_head_after_processing\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TOBA6KhYW-b",
        "outputId": "69b6ccd8-8929-474f-9d3e-07c8b27d21ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0,\n",
              "         Age   Race Marital Status T Stage  N Stage 6th Stage  \\\n",
              " 0  1.608907  White        Married       T1      N1       IIA   \n",
              " 1 -0.449611  White        Married       T2      N2      IIIA   \n",
              " 2  0.465286  White       Divorced       T3      N3      IIIC   \n",
              " 3  0.465286  White        Married       T1      N1       IIA   \n",
              " 4 -0.792697  White        Married       T2      N1       IIB   \n",
              " \n",
              "                differentiate Grade   A Stage  Tumor Size Estrogen Status  \\\n",
              " 0      Poorly differentiated     3  Regional   -1.306632        Positive   \n",
              " 1  Moderately differentiated     2  Regional    0.218417        Positive   \n",
              " 2  Moderately differentiated     2  Regional    1.595881        Positive   \n",
              " 3      Poorly differentiated     3  Regional    0.000000        Positive   \n",
              " 4      Poorly differentiated     3  Regional    0.513588        Positive   \n",
              " \n",
              "   Progesterone Status  Regional Node Examined  Reginol Node Positive  \\\n",
              " 0            Positive                1.280868              -0.618172   \n",
              " 1            Positive               -0.046684               0.164807   \n",
              " 2            Positive               -0.046684               0.556296   \n",
              " 3            Positive               -1.639745              -0.618172   \n",
              " 4            Positive               -1.506990              -0.618172   \n",
              " \n",
              "    Survival Months Status  \n",
              " 0        -0.492961  Alive  \n",
              " 1        -0.405695  Alive  \n",
              " 2         0.161530  Alive  \n",
              " 3         0.554224  Alive  \n",
              " 4        -0.929288  Alive  )"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encode categorical features with LabelEncoder\n",
        "label_encoders = {}\n",
        "for col in cat_cols:\n",
        "    le = LabelEncoder()\n",
        "    data[col] = le.fit_transform(data[col])\n",
        "    label_encoders[col] = le  # Store encoders for potential inverse transformation later\n",
        "\n",
        "# splitting data into features and target\n",
        "X = data.drop(columns=['Status'])\n",
        "y = data['Status']\n",
        "\n",
        "# splitting into training and test sets (80-20 split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnoAskxvYXll",
        "outputId": "cd217ba9-d9a0-473c-bbdf-66a74f66dae8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3219, 15), (805, 15), (3219,), (805,))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# implemening KNN from scratch\n",
        "class KNN:\n",
        "    def __init__(self, k=3):\n",
        "        self.k = k\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = [self._predict(x) for x in X]\n",
        "        return np.array(predictions)\n",
        "\n",
        "    def _predict(self, x):\n",
        "        # computed distances between x and all examples in the training set\n",
        "        distances = np.linalg.norm(self.X_train - x, axis=1)\n",
        "        # Sort by distance and return the indices of the first k neighbors\n",
        "        k_indices = np.argsort(distances)[:self.k]\n",
        "        # extracted the labels of the k nearest neighbor training samples\n",
        "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
        "        # return the most common class label among the k neighbors\n",
        "        most_common = Counter(k_nearest_labels).most_common(1)\n",
        "        return most_common[0][0]\n",
        "\n",
        "# initialize KNN with k=5 for this example\n",
        "knn = KNN(k=5)\n",
        "knn.fit(X_train.values, y_train.values)\n",
        "\n",
        "# predict on the test set\n",
        "y_pred_knn = knn.predict(X_test.values)\n",
        "\n",
        "# check the first few predictions to validate\n",
        "y_pred_knn[:10]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5h7pp8_dct7U",
        "outputId": "d7b0af39-3316-4884-a84a-bf5039a67495"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "# calculate performance metrics for KNN\n",
        "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
        "precision_knn = precision_score(y_test, y_pred_knn, average='binary')  # Adjust `average` based on your labels\n",
        "recall_knn = recall_score(y_test, y_pred_knn, average='binary')\n",
        "f1_knn = f1_score(y_test, y_pred_knn, average='binary')\n",
        "\n",
        "# print the classification report and confusion matrix\n",
        "print(\"KNN Classification Report:\\n\", classification_report(y_test, y_pred_knn))\n",
        "print(\"KNN Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_knn))\n",
        "\n",
        "# Store results\n",
        "knn_results = {\n",
        "    \"Model\": \"KNN\",\n",
        "    \"Accuracy\": accuracy_knn,\n",
        "    \"Precision\": precision_knn,\n",
        "    \"Recall\": recall_knn,\n",
        "    \"F1 Score\": f1_knn\n",
        "}\n",
        "\n",
        "knn_results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GV87VzRiUjZ",
        "outputId": "6dc77b46-a82e-4557-956a-724e5f3aab0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.97      0.93       685\n",
            "           1       0.70      0.35      0.47       120\n",
            "\n",
            "    accuracy                           0.88       805\n",
            "   macro avg       0.80      0.66      0.70       805\n",
            "weighted avg       0.87      0.88      0.86       805\n",
            "\n",
            "KNN Confusion Matrix:\n",
            " [[667  18]\n",
            " [ 78  42]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Model': 'KNN',\n",
              " 'Accuracy': 0.8807453416149068,\n",
              " 'Precision': 0.7,\n",
              " 'Recall': 0.35,\n",
              " 'F1 Score': 0.4666666666666667}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Align columns between training and test sets (after one-hot encoding)\n",
        "X_train, X_test = X_train.align(X_test, join='inner', axis=1)\n"
      ],
      "metadata": {
        "id": "6X_JXHhT-RLQ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Train Naïve Bayes\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train, y_train)\n",
        "y_pred_nb = nb.predict(X_test)\n",
        "\n",
        "# Train Decision Tree\n",
        "dt = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "y_pred_dt = dt.predict(X_test)\n",
        "\n",
        "# Evaluate models\n",
        "nb_results = {\n",
        "    \"Model\": \"Naïve Bayes\",\n",
        "    \"Accuracy\": accuracy_score(y_test, y_pred_nb),\n",
        "    \"Precision\": precision_score(y_test, y_pred_nb, average='binary'),\n",
        "    \"Recall\": recall_score(y_test, y_pred_nb, average='binary'),\n",
        "    \"F1 Score\": f1_score(y_test, y_pred_nb, average='binary')\n",
        "}\n",
        "\n",
        "dt_results = {\n",
        "    \"Model\": \"Decision Tree\",\n",
        "    \"Accuracy\": accuracy_score(y_test, y_pred_dt),\n",
        "    \"Precision\": precision_score(y_test, y_pred_dt, average='binary'),\n",
        "    \"Recall\": recall_score(y_test, y_pred_dt, average='binary'),\n",
        "    \"F1 Score\": f1_score(y_test, y_pred_dt, average='binary')\n",
        "}\n",
        "\n",
        "nb_results, dt_results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-9qahrrmiwH",
        "outputId": "56c62004-7d0a-4c72-cf1c-da1873c3353e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'Model': 'Naïve Bayes',\n",
              "  'Accuracy': 0.8385093167701864,\n",
              "  'Precision': 0.4603174603174603,\n",
              "  'Recall': 0.48333333333333334,\n",
              "  'F1 Score': 0.4715447154471545},\n",
              " {'Model': 'Decision Tree',\n",
              "  'Accuracy': 0.8459627329192546,\n",
              "  'Precision': 0.48360655737704916,\n",
              "  'Recall': 0.49166666666666664,\n",
              "  'F1 Score': 0.48760330578512395})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Step 1: train the baseline Random Forest model\n",
        "rf_baseline = RandomForestClassifier(random_state=42)\n",
        "rf_baseline.fit(X_train, y_train)\n",
        "y_pred_rf_baseline = rf_baseline.predict(X_test)\n",
        "\n",
        "# Step 2: evaluate the baseline Random Forest model\n",
        "rf_baseline_results = {\n",
        "    \"Model\": \"Random Forest (Baseline)\",\n",
        "    \"Accuracy\": accuracy_score(y_test, y_pred_rf_baseline),\n",
        "    \"Precision\": precision_score(y_test, y_pred_rf_baseline, average='binary'),\n",
        "    \"Recall\": recall_score(y_test, y_pred_rf_baseline, average='binary'),\n",
        "    \"F1 Score\": f1_score(y_test, y_pred_rf_baseline, average='binary')\n",
        "}\n",
        "\n",
        "print(\"Baseline Random Forest Results:\", rf_baseline_results)\n",
        "\n",
        "# Step 3: hyperparameter Tuning using GridSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define parameter grid for tuning\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# set up GridSearchCV\n",
        "grid_search_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, cv=5, scoring='accuracy')\n",
        "grid_search_rf.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: retrieve the best parameters and score\n",
        "best_params_rf = grid_search_rf.best_params_\n",
        "print(\"Best Parameters:\", best_params_rf)\n",
        "\n",
        "# Step 5: train and evaluate Random Forest with best parameters\n",
        "rf_tuned = RandomForestClassifier(**best_params_rf, random_state=42)\n",
        "rf_tuned.fit(X_train, y_train)\n",
        "y_pred_rf_tuned = rf_tuned.predict(X_test)\n",
        "\n",
        "# Step 6: evaluate the tuned Random Forest model\n",
        "rf_tuned_results = {\n",
        "    \"Model\": \"Random Forest (Tuned)\",\n",
        "    \"Accuracy\": accuracy_score(y_test, y_pred_rf_tuned),\n",
        "    \"Precision\": precision_score(y_test, y_pred_rf_tuned, average='binary'),\n",
        "    \"Recall\": recall_score(y_test, y_pred_rf_tuned, average='binary'),\n",
        "    \"F1 Score\": f1_score(y_test, y_pred_rf_tuned, average='binary')\n",
        "}\n",
        "\n",
        "print(\"Tuned Random Forest Results:\", rf_tuned_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8MRwwcGnIMh",
        "outputId": "5d96f0b2-c62d-4154-8883-0ea9fe9feeab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Random Forest Results: {'Model': 'Random Forest (Baseline)', 'Accuracy': 0.9142857142857143, 'Precision': 0.8227848101265823, 'Recall': 0.5416666666666666, 'F1 Score': 0.6532663316582915}\n",
            "Best Parameters: {'max_depth': 20, 'min_samples_split': 5, 'n_estimators': 200}\n",
            "Tuned Random Forest Results: {'Model': 'Random Forest (Tuned)', 'Accuracy': 0.9142857142857143, 'Precision': 0.8311688311688312, 'Recall': 0.5333333333333333, 'F1 Score': 0.649746192893401}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Apply SMOTE to oversample the minority class in the training set\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"Original class distribution:\", Counter(y_train))\n",
        "print(\"Resampled class distribution:\", Counter(y_train_resampled))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ats5GgO5oi-j",
        "outputId": "64d3d1bb-f576-4352-e671-d1eb80c76bf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original class distribution: Counter({0: 2723, 1: 496})\n",
            "Resampled class distribution: Counter({0: 2723, 1: 2723})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# recursive feature elimination using RandomForest as a base estimator\n",
        "selector = RFE(estimator=RandomForestClassifier(random_state=42), n_features_to_select=10, step=1)\n",
        "selector = selector.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Select the top features based on RFE\n",
        "X_train_selected = selector.transform(X_train_resampled)\n",
        "X_test_selected = selector.transform(X_test)\n"
      ],
      "metadata": {
        "id": "Rmoin2XropBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the Random Forest classifier on resampled and selected data\n",
        "rf_tuned = RandomForestClassifier(\n",
        "    n_estimators=200, max_depth=20, min_samples_split=5, random_state=42\n",
        ")\n",
        "rf_tuned.fit(X_train_selected, y_train_resampled)\n",
        "y_pred_rf_tuned = rf_tuned.predict(X_test_selected)\n",
        "\n",
        "# evaluate the Random Forest classifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print(\"Random Forest (Tuned) Classification Report:\\n\", classification_report(y_test, y_pred_rf_tuned))\n",
        "print(\"Random Forest (Tuned) Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf_tuned))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EW6ZzucEovzb",
        "outputId": "df8612d8-1760-4e01-f245-f2af513d53f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest (Tuned) Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.95      0.94       685\n",
            "           1       0.67      0.63      0.65       120\n",
            "\n",
            "    accuracy                           0.90       805\n",
            "   macro avg       0.80      0.79      0.80       805\n",
            "weighted avg       0.90      0.90      0.90       805\n",
            "\n",
            "Random Forest (Tuned) Confusion Matrix:\n",
            " [[648  37]\n",
            " [ 44  76]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# tried further tuning Random Forest with cross-validation\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [10, 15, 20],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "grid_search_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, cv=5, scoring='f1')\n",
        "grid_search_rf.fit(X_train_selected, y_train_resampled)\n",
        "\n",
        "print(\"Best Parameters for Random Forest:\", grid_search_rf.best_params_)\n",
        "print(\"Best Cross-Validation Score:\", grid_search_rf.best_score_)\n",
        "\n",
        "# retrain Random Forest with best parameters\n",
        "rf_optimized = RandomForestClassifier(**grid_search_rf.best_params_, random_state=42)\n",
        "rf_optimized.fit(X_train_selected, y_train_resampled)\n",
        "y_pred_rf_optimized = rf_optimized.predict(X_test_selected)\n",
        "\n",
        "# evaluating the optimized Random Forest model\n",
        "print(\"Optimized Random Forest Classification Report:\\n\", classification_report(y_test, y_pred_rf_optimized))\n",
        "print(\"Optimized Random Forest Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf_optimized))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvcFOHTAo_x_",
        "outputId": "2f1f82ca-91cc-468a-b382-076c772d5ff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters for Random Forest: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 300}\n",
            "Best Cross-Validation Score: 0.9198255229073627\n",
            "Optimized Random Forest Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.95      0.94       685\n",
            "           1       0.67      0.62      0.65       120\n",
            "\n",
            "    accuracy                           0.90       805\n",
            "   macro avg       0.80      0.79      0.79       805\n",
            "weighted avg       0.90      0.90      0.90       805\n",
            "\n",
            "Optimized Random Forest Confusion Matrix:\n",
            " [[648  37]\n",
            " [ 45  75]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# C4.5 Decision Tree - Already covered with `criterion='entropy'`\n",
        "# Training and evaluating Decision Tree (C4.5)\n",
        "dt = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "y_pred_dt = dt.predict(X_test)\n",
        "\n",
        "# evaluate C4.5 Decision Tree\n",
        "dt_results = {\n",
        "    \"Model\": \"Decision Tree (C4.5)\",\n",
        "    \"Accuracy\": accuracy_score(y_test, y_pred_dt),\n",
        "    \"Precision\": precision_score(y_test, y_pred_dt, average='binary'),\n",
        "    \"Recall\": recall_score(y_test, y_pred_dt, average='binary'),\n",
        "    \"F1 Score\": f1_score(y_test, y_pred_dt, average='binary')\n",
        "}\n",
        "print(\"C4.5 Decision Tree Results:\", dt_results)\n",
        "\n",
        "\n",
        "#  **Gradient Boosting**\n",
        "# Train Gradient Boosting model\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "gb.fit(X_train, y_train)\n",
        "y_pred_gb = gb.predict(X_test)\n",
        "\n",
        "# evaluate Gradient Boosting model\n",
        "gb_results = {\n",
        "    \"Model\": \"Gradient Boosting\",\n",
        "    \"Accuracy\": accuracy_score(y_test, y_pred_gb),\n",
        "    \"Precision\": precision_score(y_test, y_pred_gb, average='binary'),\n",
        "    \"Recall\": recall_score(y_test, y_pred_gb, average='binary'),\n",
        "    \"F1 Score\": f1_score(y_test, y_pred_gb, average='binary')\n",
        "}\n",
        "print(\"Gradient Boosting Results:\", gb_results)\n",
        "\n",
        "\n",
        "# Neural Networks (MLPClassifier)**\n",
        "# Train Neural Network model (MLP)\n",
        "mlp = MLPClassifier(random_state=42, max_iter=300)\n",
        "mlp.fit(X_train, y_train)\n",
        "y_pred_mlp = mlp.predict(X_test)\n",
        "\n",
        "# evaluating Neural Network model\n",
        "mlp_results = {\n",
        "    \"Model\": \"Neural Network (MLP)\",\n",
        "    \"Accuracy\": accuracy_score(y_test, y_pred_mlp),\n",
        "    \"Precision\": precision_score(y_test, y_pred_mlp, average='binary'),\n",
        "    \"Recall\": recall_score(y_test, y_pred_mlp, average='binary'),\n",
        "    \"F1 Score\": f1_score(y_test, y_pred_mlp, average='binary')\n",
        "}\n",
        "print(\"Neural Network Results:\", mlp_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ncf1PSZAInc",
        "outputId": "a87f2dea-cbe7-4b36-efe4-366ae0ac89b2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C4.5 Decision Tree Results: {'Model': 'Decision Tree (C4.5)', 'Accuracy': 0.8459627329192546, 'Precision': 0.48360655737704916, 'Recall': 0.49166666666666664, 'F1 Score': 0.48760330578512395}\n",
            "Gradient Boosting Results: {'Model': 'Gradient Boosting', 'Accuracy': 0.915527950310559, 'Precision': 0.8421052631578947, 'Recall': 0.5333333333333333, 'F1 Score': 0.6530612244897959}\n",
            "Neural Network Results: {'Model': 'Neural Network (MLP)', 'Accuracy': 0.9080745341614906, 'Precision': 0.8108108108108109, 'Recall': 0.5, 'F1 Score': 0.6185567010309279}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# parameter grid for Gradient Boosting\n",
        "param_grid_gb = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'learning_rate': [0.01, 0.1],\n",
        "    'max_depth': [3, 5]\n",
        "}\n",
        "\n",
        "# set up GridSearchCV for Gradient Boosting\n",
        "grid_search_gb = GridSearchCV(GradientBoostingClassifier(random_state=42), param_grid_gb, cv=5, scoring='accuracy')\n",
        "grid_search_gb.fit(X_train, y_train)\n",
        "\n",
        "best_params_gb = grid_search_gb.best_params_\n",
        "print(\"Best Parameters for Gradient Boosting:\", best_params_gb)\n",
        "\n",
        "# train the model with best parameters\n",
        "best_gb = GradientBoostingClassifier(**best_params_gb, random_state=42)\n",
        "best_gb.fit(X_train, y_train)\n",
        "y_pred_best_gb = best_gb.predict(X_test)\n",
        "\n",
        "# evaluate tuned Gradient Boosting model\n",
        "best_gb_results = {\n",
        "    \"Model\": \"Tuned Gradient Boosting\",\n",
        "    \"Accuracy\": accuracy_score(y_test, y_pred_best_gb),\n",
        "    \"Precision\": precision_score(y_test, y_pred_best_gb, average='binary'),\n",
        "    \"Recall\": recall_score(y_test, y_pred_best_gb, average='binary'),\n",
        "    \"F1 Score\": f1_score(y_test, y_pred_best_gb, average='binary')\n",
        "}\n",
        "print(\"Tuned Gradient Boosting Results:\", best_gb_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1KL0mY5Al4H",
        "outputId": "40fb7075-da2b-476c-dd4f-e093ceaeaec0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters for Gradient Boosting: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200}\n",
            "Tuned Gradient Boosting Results: {'Model': 'Tuned Gradient Boosting', 'Accuracy': 0.9080745341614906, 'Precision': 0.8484848484848485, 'Recall': 0.4666666666666667, 'F1 Score': 0.6021505376344086}\n"
          ]
        }
      ]
    }
  ]
}